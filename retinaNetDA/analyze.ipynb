{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
    "    Normalizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "\n",
    "assert torch.__version__.split('.')[0] == '1'\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--epochs'], dest='epochs', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='Number of epochs', metavar=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args=None\n",
    "parser = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
    "\n",
    "parser.add_argument('--dataset', help='Dataset type, must be one of csv or coco.',default='coco')\n",
    "parser.add_argument('--coco_path',help='Path to COCO directory',default='../patch_testing')\n",
    "parser.add_argument('--csv_train', help='Path to file containing training annotations (see readme)')\n",
    "parser.add_argument('--csv_classes', help='Path to file containing class list (see readme)')\n",
    "parser.add_argument('--csv_val', help='Path to file containing validation annotations (optional, see readme)')\n",
    "\n",
    "parser.add_argument('--depth', help='Resnet depth, must be one of 18, 34, 50, 101, 152', type=int, default=50)\n",
    "parser.add_argument('--epochs', help='Number of epochs', type=int, default=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = CocoDataset('/data112/MIDOG2022', set_name='patch_training.json',\n",
    "                                    transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "sampler = AspectRatioBasedSampler(dataset_train, batch_size=2, drop_last=False)\n",
    "dataloader_train = DataLoader(dataset_train, num_workers=3, collate_fn=collater, batch_sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=30.34s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "coco= COCO('/data112/MIDOG2022/patch_training.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = coco.getImgIds()\n",
    "image_index = 1\n",
    "image_info = coco.loadImgs(image_ids[image_index])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_756_872.png'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_info[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = coco.loadCats(coco.getCatIds())\n",
    "categories.sort(key=lambda x: x['id'])\n",
    "\n",
    "classes             = {}\n",
    "coco_labels         = {}\n",
    "coco_labels_inverse = {}\n",
    "for c in categories:\n",
    "    coco_labels[len(self.classes)] = c['id']\n",
    "    coco_labels_inverse[c['id']] = len(self.classes)\n",
    "    classes[c['name']] = len(self.classes)\n",
    "\n",
    "# also load the reverse (label -> name)\n",
    "labels = {}\n",
    "for key, value in classes.items():\n",
    "    labels[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_label_to_label(self, coco_label):\n",
    "        return coco_labels_inverse[coco_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_ids = coco.getAnnIds(imgIds=image_ids[image_index], iscrowd=False)\n",
    "annotations     = np.zeros((0, 5))\n",
    "coco_annotations = coco.loadAnns(annotations_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'iscrowd': 0,\n",
       "  'area': 2500,\n",
       "  'bbox': [231, 231, 50, 50],\n",
       "  'category_id': 1,\n",
       "  'image_id': 2,\n",
       "  'id': 2,\n",
       "  'scanner_id': 'unknown',\n",
       "  'tumor_label': 'breast'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, a in enumerate(coco_annotations):\n",
    "\n",
    "            # some annotations have basically no width / height, skip them\n",
    "            if a['bbox'][2] < 1 or a['bbox'][3] < 1:\n",
    "                continue\n",
    "\n",
    "            annotation        = np.zeros((1, 5))\n",
    "            annotation[0, :4] = a['bbox']\n",
    "            annotation[0, 4]  = coco_label_to_label(a['category_id'])\n",
    "            annotations       = np.append(annotations, annotation, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('open-mmlab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "baa5d5bd670d031f3931a68c1b62506e6ccf5114cea5ef4fcc7b1bc94bda918a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
